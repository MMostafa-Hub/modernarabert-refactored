{
  "configuration": {
    "model": "arabert",
    "dataset": "asas-ai/ANERCorp",
    "epochs": 200,
    "learning_rate": 8e-05,
    "batch_size": 16,
    "fine_tune": "head-only",
    "patience": 10,
    "timestamp": "2025-08-22T16:16:20.934643"
  },
  "results": {
    "accuracy": 0.8768951841359773,
    "macro_f1_score": 0.565708131937237,
    "precision": 0.5474120528034843,
    "recall": 0.599872943458946,
    "weighted_f1_score": 0.8834149714757052,
    "loss": 0.0794927179813385,
    "runtime_seconds": 1.2975,
    "samples_per_second": 712.932,
    "steps_per_second": 44.703
  },
  "detailed_analysis": {
    "per_label_metrics": {
      "B-LOC": {
        "precision": 0.5850340136054422,
        "recall": 0.6485671191553545,
        "f1-score": 0.6151645207439199,
        "support": 663.0
      },
      "B-MISC": {
        "precision": 0.4819277108433735,
        "recall": 0.3448275862068966,
        "f1-score": 0.4020100502512563,
        "support": 232.0
      },
      "B-ORG": {
        "precision": 0.4141914191419142,
        "recall": 0.5653153153153153,
        "f1-score": 0.4780952380952381,
        "support": 444.0
      },
      "B-PERS": {
        "precision": 0.6493092454835282,
        "recall": 0.7326139088729017,
        "f1-score": 0.6884507042253522,
        "support": 834.0
      },
      "I-LOC": {
        "precision": 0.43258426966292135,
        "recall": 0.6326291079812206,
        "f1-score": 0.5138226882745471,
        "support": 852.0
      },
      "I-MISC": {
        "precision": 0.3424124513618677,
        "recall": 0.30344827586206896,
        "f1-score": 0.3217550274223035,
        "support": 580.0
      },
      "I-ORG": {
        "precision": 0.33636363636363636,
        "recall": 0.5408426483233018,
        "f1-score": 0.4147708539399934,
        "support": 1163.0
      },
      "I-PERS": {
        "precision": 0.7301484828921885,
        "recall": 0.7077596996245307,
        "f1-score": 0.7187797902764538,
        "support": 1598.0
      },
      "O": {
        "precision": 0.9547372458764863,
        "recall": 0.9228528297889245,
        "f1-score": 0.9385243142060681,
        "support": 37759.0
      },
      "accuracy": 0.8768951841359773,
      "macro avg": {
        "precision": 0.5474120528034843,
        "recall": 0.599872943458946,
        "f1-score": 0.565708131937237,
        "support": 44125.0
      },
      "weighted avg": {
        "precision": 0.8929215309260944,
        "recall": 0.8768951841359773,
        "f1-score": 0.8834149714757052,
        "support": 44125.0
      }
    },
    "confusion_matrix": [
      [
        430,
        0,
        22,
        12,
        5,
        2,
        10,
        2,
        180
      ],
      [
        6,
        80,
        20,
        4,
        1,
        6,
        2,
        2,
        111
      ],
      [
        30,
        6,
        251,
        19,
        1,
        1,
        20,
        6,
        110
      ],
      [
        10,
        8,
        24,
        611,
        1,
        0,
        1,
        39,
        140
      ],
      [
        16,
        0,
        0,
        3,
        539,
        8,
        59,
        14,
        213
      ],
      [
        11,
        7,
        5,
        1,
        38,
        176,
        70,
        14,
        258
      ],
      [
        8,
        1,
        31,
        4,
        83,
        17,
        629,
        51,
        339
      ],
      [
        4,
        2,
        4,
        83,
        33,
        10,
        30,
        1131,
        301
      ],
      [
        220,
        62,
        249,
        204,
        545,
        294,
        1049,
        290,
        34846
      ]
    ],
    "confusion_matrix_labels": [
      "B-LOC",
      "B-MISC",
      "B-ORG",
      "B-PERS",
      "I-LOC",
      "I-MISC",
      "I-ORG",
      "I-PERS",
      "O"
    ]
  },
  "memory_usage": {
    "peak_ram_gb": 1.5275344848632812,
    "peak_ram_percent": 13.3,
    "peak_vram_gb": 0.5190997123718262,
    "peak_vram_percent": 1.6358591144360712,
    "vram_total_gb": 31.7325439453125
  }
}