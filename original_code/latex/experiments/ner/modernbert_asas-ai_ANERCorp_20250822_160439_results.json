{
  "configuration": {
    "model": "modernbert",
    "dataset": "asas-ai/ANERCorp",
    "epochs": 200,
    "learning_rate": 8e-05,
    "batch_size": 16,
    "fine_tune": "head-only",
    "patience": 10,
    "timestamp": "2025-08-22T16:11:55.207323"
  },
  "results": {
    "accuracy": 0.8129235095393388,
    "macro_f1_score": 0.37956290552050836,
    "precision": 0.33832504873713987,
    "recall": 0.45307542663901074,
    "weighted_f1_score": 0.8288536762040162,
    "loss": 0.11994800716638565,
    "runtime_seconds": 2.0535,
    "samples_per_second": 450.451,
    "steps_per_second": 28.245
  },
  "detailed_analysis": {
    "per_label_metrics": {
      "B-LOC": {
        "precision": 0.30622710622710625,
        "recall": 0.6362252663622526,
        "f1-score": 0.4134520276953511,
        "support": 657.0
      },
      "B-MISC": {
        "precision": 0.175,
        "recall": 0.3017241379310345,
        "f1-score": 0.22151898734177214,
        "support": 232.0
      },
      "B-ORG": {
        "precision": 0.23759398496240602,
        "recall": 0.3607305936073059,
        "f1-score": 0.28649138712601996,
        "support": 438.0
      },
      "B-PERS": {
        "precision": 0.3204819277108434,
        "recall": 0.4784172661870504,
        "f1-score": 0.3838383838383838,
        "support": 834.0
      },
      "I-LOC": {
        "precision": 0.3012644310060473,
        "recall": 0.525911708253359,
        "f1-score": 0.38308283816847255,
        "support": 1042.0
      },
      "I-MISC": {
        "precision": 0.13721413721413722,
        "recall": 0.21639344262295082,
        "f1-score": 0.16793893129770993,
        "support": 610.0
      },
      "I-ORG": {
        "precision": 0.2282696994313566,
        "recall": 0.22570281124497993,
        "f1-score": 0.22697899838449112,
        "support": 1245.0
      },
      "I-PERS": {
        "precision": 0.39764896635589786,
        "recall": 0.45416666666666666,
        "f1-score": 0.4240328506591744,
        "support": 2160.0
      },
      "O": {
        "precision": 0.9412251857264645,
        "recall": 0.8784069468754973,
        "f1-score": 0.9087317451732004,
        "support": 43991.0
      },
      "accuracy": 0.8129235095393388,
      "macro avg": {
        "precision": 0.33832504873713987,
        "recall": 0.45307542663901074,
        "f1-score": 0.37956290552050836,
        "support": 51209.0
      },
      "weighted avg": {
        "precision": 0.8506182927051532,
        "recall": 0.8129235095393388,
        "f1-score": 0.8288536762040162,
        "support": 51209.0
      }
    },
    "confusion_matrix": [
      [
        418,
        6,
        19,
        22,
        22,
        1,
        5,
        10,
        154
      ],
      [
        19,
        70,
        12,
        18,
        3,
        3,
        0,
        11,
        96
      ],
      [
        60,
        13,
        158,
        46,
        3,
        2,
        14,
        10,
        132
      ],
      [
        41,
        12,
        37,
        399,
        5,
        7,
        6,
        92,
        235
      ],
      [
        34,
        0,
        2,
        5,
        548,
        19,
        50,
        65,
        319
      ],
      [
        29,
        17,
        5,
        11,
        63,
        132,
        59,
        73,
        221
      ],
      [
        48,
        6,
        30,
        20,
        142,
        51,
        281,
        119,
        548
      ],
      [
        22,
        4,
        10,
        176,
        119,
        50,
        90,
        981,
        708
      ],
      [
        694,
        272,
        392,
        548,
        914,
        697,
        726,
        1106,
        38642
      ]
    ],
    "confusion_matrix_labels": [
      "B-LOC",
      "B-MISC",
      "B-ORG",
      "B-PERS",
      "I-LOC",
      "I-MISC",
      "I-ORG",
      "I-PERS",
      "O"
    ]
  },
  "memory_usage": {
    "peak_ram_gb": 1.4934349060058594,
    "peak_ram_percent": 13.1,
    "peak_vram_gb": 0.8260331153869629,
    "peak_vram_percent": 2.603110285801664,
    "vram_total_gb": 31.7325439453125
  }
}