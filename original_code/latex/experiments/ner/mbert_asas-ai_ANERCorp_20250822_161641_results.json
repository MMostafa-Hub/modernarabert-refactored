{
  "configuration": {
    "model": "mbert",
    "dataset": "asas-ai/ANERCorp",
    "epochs": 200,
    "learning_rate": 8e-05,
    "batch_size": 16,
    "fine_tune": "head-only",
    "patience": 10,
    "timestamp": "2025-08-22T16:22:32.503670"
  },
  "results": {
    "accuracy": 0.9069159503942112,
    "macro_f1_score": 0.6399100105360592,
    "precision": 0.5901428361566964,
    "recall": 0.7125253636632356,
    "weighted_f1_score": 0.9128095111425406,
    "loss": 0.05227448046207428,
    "runtime_seconds": 1.35,
    "samples_per_second": 685.162,
    "steps_per_second": 42.962
  },
  "detailed_analysis": {
    "per_label_metrics": {
      "B-LOC": {
        "precision": 0.6438202247191012,
        "recall": 0.8668683812405447,
        "f1-score": 0.7388781431334622,
        "support": 661.0
      },
      "B-MISC": {
        "precision": 0.3045822102425876,
        "recall": 0.4870689655172414,
        "f1-score": 0.3747927031509121,
        "support": 232.0
      },
      "B-ORG": {
        "precision": 0.38346883468834686,
        "recall": 0.6446469248291572,
        "f1-score": 0.48088360237892946,
        "support": 439.0
      },
      "B-PERS": {
        "precision": 0.6659979939819458,
        "recall": 0.7961630695443646,
        "f1-score": 0.7252867285636264,
        "support": 834.0
      },
      "I-LOC": {
        "precision": 0.639266304347826,
        "recall": 0.8447037701974865,
        "f1-score": 0.7277648878576953,
        "support": 1114.0
      },
      "I-MISC": {
        "precision": 0.38943894389438943,
        "recall": 0.3710691823899371,
        "f1-score": 0.38003220611916266,
        "support": 636.0
      },
      "I-ORG": {
        "precision": 0.4621700879765396,
        "recall": 0.6199842643587726,
        "f1-score": 0.5295698924731183,
        "support": 1271.0
      },
      "I-PERS": {
        "precision": 0.843781768891901,
        "recall": 0.8426395939086294,
        "f1-score": 0.8432102946156451,
        "support": 2955.0
      },
      "O": {
        "precision": 0.9787591566676294,
        "recall": 0.9395841209829867,
        "f1-score": 0.9587716365319822,
        "support": 39675.0
      },
      "accuracy": 0.9069159503942112,
      "macro avg": {
        "precision": 0.5901428361566964,
        "recall": 0.7125253636632356,
        "f1-score": 0.6399100105360592,
        "support": 47817.0
      },
      "weighted avg": {
        "precision": 0.9221177001436098,
        "recall": 0.9069159503942112,
        "f1-score": 0.9128095111425406,
        "support": 47817.0
      }
    },
    "confusion_matrix": [
      [
        573,
        8,
        21,
        19,
        1,
        0,
        2,
        1,
        36
      ],
      [
        13,
        113,
        38,
        15,
        0,
        1,
        1,
        3,
        48
      ],
      [
        41,
        14,
        283,
        29,
        2,
        0,
        5,
        3,
        62
      ],
      [
        12,
        18,
        36,
        664,
        0,
        1,
        0,
        39,
        64
      ],
      [
        17,
        1,
        0,
        2,
        941,
        11,
        45,
        40,
        57
      ],
      [
        16,
        20,
        5,
        2,
        35,
        236,
        119,
        38,
        165
      ],
      [
        4,
        3,
        42,
        9,
        78,
        36,
        788,
        109,
        202
      ],
      [
        3,
        8,
        4,
        67,
        52,
        69,
        87,
        2490,
        175
      ],
      [
        211,
        186,
        309,
        190,
        363,
        252,
        658,
        228,
        37278
      ]
    ],
    "confusion_matrix_labels": [
      "B-LOC",
      "B-MISC",
      "B-ORG",
      "B-PERS",
      "I-LOC",
      "I-MISC",
      "I-ORG",
      "I-PERS",
      "O"
    ]
  },
  "memory_usage": {
    "peak_ram_gb": 1.60150146484375,
    "peak_ram_percent": 12.7,
    "peak_vram_gb": 0.6773028373718262,
    "peak_vram_percent": 2.1344107756979147,
    "vram_total_gb": 31.7325439453125
  }
}