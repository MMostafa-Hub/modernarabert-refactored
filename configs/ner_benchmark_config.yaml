# Named Entity Recognition Benchmarking Configuration
# For evaluating ModernAraBERT on Arabic NER tasks

# Model Configuration
model:
  model_name: "modernarabert"  # Options: modernarabert, arabert, mbert
  model_path: "gizadatateam/ModernAraBERT"  # Hugging Face model path or local path
  freeze_encoder: true  # Freeze encoder, train only NER head
  
# Dataset Configuration
dataset:
  name: "anercorp"  # Primary dataset: ANERCorp
  source: "CAMeL-Lab/ANERcorp"  # Hugging Face dataset
  data_dir: "./data/benchmarks/ner"
  
  # Entity types
  entity_types:
    - "O"  # Outside
    - "B-PER"  # Person
    - "I-PER"
    - "B-LOC"  # Location
    - "I-LOC"
    - "B-ORG"  # Organization
    - "I-ORG"
    - "B-MISC"  # Miscellaneous
    - "I-MISC"
  
  # Tagging scheme
  tagging_scheme: "IOB2"  # IOB2 format
  
  # Subword handling strategy
  subword_labeling: "first_token_only"  # Options: first_token_only, all_tokens, ignore
  label_all_tokens: false  # If false, continuation tokens are -100 (ignored in loss)
  
  # Preprocessing
  preprocessing:
    max_length: 512
    stride: 128  # For handling long sequences
    padding: "max_length"
    truncation: true

# Training Configuration
training:
  # Optimization
  learning_rate: 2.0e-5
  batch_size: 16
  num_epochs: 5  # NER typically converges quickly
  weight_decay: 0.01
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 3  # Shorter patience for NER
    monitor: "val_f1"
    mode: "max"
  
  # Regularization
  dropout: 0.1
  
  # Device
  device: "cuda"
  mixed_precision: "fp16"
  
  # Optimization
  optimizer: "adamw"
  adam_beta1: 0.9
  adam_beta2: 0.999
  max_grad_norm: 1.0
  
  # Learning rate schedule
  lr_scheduler: "linear"
  warmup_ratio: 0.1
  
  # Class weights (for imbalanced classes)
  use_class_weights: true
  
  # Seeds
  seed: 42

# Evaluation Configuration
evaluation:
  # Primary metric: Micro F1 (entity-level)
  metrics:
    - "accuracy"  # Token-level accuracy
    - "precision"  # Entity-level precision
    - "recall"  # Entity-level recall
    - "micro_f1"  # Primary metric for paper
    - "macro_f1"  # Equal weight to all classes
    - "per_entity_f1"  # F1 for each entity type
  
  # Evaluation level
  eval_level: "entity"  # Options: token, entity
  
  batch_size: 32
  
  # Ignore special tokens in evaluation
  ignore_labels: [-100]
  
  # Which split to use for final evaluation
  use_test_set: true

# Logging and Output
logging:
  log_dir: "./logs/ner"
  log_file: "NER_Benchmark_{model}_{dataset}_{timestamp}.log"
  log_level: "INFO"
  
  # Save predictions
  save_predictions: true
  predictions_file: "./results/ner/{model}_{dataset}_predictions.csv"
  
  # Save metrics
  save_metrics: true
  metrics_file: "./results/ner/{model}_{dataset}_metrics.json"
  
  # Save per-entity metrics
  save_entity_metrics: true
  entity_metrics_file: "./results/ner/{model}_{dataset}_entity_metrics.json"

# Checkpointing
checkpoints:
  save_checkpoints: true
  checkpoint_dir: "./checkpoints/ner"
  save_best_only: true
  monitor: "val_micro_f1"
  mode: "max"

# System Configuration
system:
  num_workers: 2
  pin_memory: true
  dataloader_persistent_workers: false
  
  # Memory tracking
  track_memory: true
  log_memory_usage: true
  
  # Performance tracking
  track_throughput: true  # Samples per second

# Benchmark-specific Options
benchmark:
  # Run inference only (no training)
  inference_only: false
  
  # Load pretrained checkpoint
  load_checkpoint: null
  
  # Continue from checkpoint
  continue_from_checkpoint: false
  
  # Fine-tuning strategy
  fine_tune_strategy: "head_only"  # Options: head_only, full_model, partial
  
  # If partial fine-tuning, specify layers
  partial_fine_tune_layers: null  # e.g., [20, 21, 22] for top 3 layers

# Post-processing
post_processing:
  # Entity extraction rules
  merge_subwords: true  # Merge subword predictions
  use_heuristics: false  # Apply rule-based post-processing
  
  # Confidence thresholding
  min_confidence: 0.0  # Minimum prediction confidence

# Analysis Options
analysis:
  # Error analysis
  perform_error_analysis: true
  error_analysis_file: "./results/ner/{model}_{dataset}_errors.txt"
  
  # Confusion matrix
  save_confusion_matrix: true
  confusion_matrix_file: "./results/ner/{model}_{dataset}_confusion.png"
  
  # Per-entity analysis
  per_entity_analysis: true

