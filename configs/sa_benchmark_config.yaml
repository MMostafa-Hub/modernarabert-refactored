# Sentiment Analysis Benchmarking Configuration
# For evaluating ModernAraBERT on Arabic sentiment analysis tasks

# Model Configuration
model:
  model_name: "modernarabert"  # Options: modernarabert, arabert, mbert, arabert2, marbert
  model_path: "gizadatateam/ModernAraBERT"  # Hugging Face model path or local path
  freeze_encoder: true  # Freeze encoder, train only classification head
  
# Dataset Configuration
dataset:
  name: "hard"  # Options: hard, astd, labr, ajgt
  data_dir: "./data/benchmarks/sa"
  
  # Dataset-specific settings
  datasets:
    hard:
      source: "Elnagara/hard"
      subset: "plain_text"
      num_classes: 2  # Binary: positive, negative (excluding neutral)
      exclude_neutral: true  # Exclude 3-star reviews
      
    astd:
      source: "local"  # Downloaded locally
      num_classes: 2
      
    labr:
      source: "labr"
      subset: "unbalanced_binary"
      num_classes: 2
      
    ajgt:
      source: "local"  # Excel file
      url: "https://github.com/komari6/Arabic-twitter-corpus-AJGT"
      num_classes: 2
  
  # Data splits (if not predefined)
  split_ratios:
    train: 0.6
    validation: 0.2
    test: 0.2
  
  # Preprocessing
  preprocessing:
    normalize_arabic: true
    remove_diacritics: true
    remove_urls: true
    remove_mentions: true
    remove_hashtags: false
    lowercase: false  # Not applicable for Arabic
    max_length: 512

# Training Configuration
training:
  # Optimization
  learning_rate: 2.0e-5
  batch_size: 16
  num_epochs: 50  # Maximum epochs
  weight_decay: 0.01
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    monitor: "val_loss"
    mode: "min"
  
  # Regularization
  dropout: 0.1
  
  # Device
  device: "cuda"
  mixed_precision: "fp16"
  
  # Optimization
  optimizer: "adamw"
  adam_beta1: 0.9
  adam_beta2: 0.999
  max_grad_norm: 1.0
  
  # Learning rate schedule
  lr_scheduler: "linear"
  warmup_ratio: 0.1
  
  # Seeds
  seed: 42

# Evaluation Configuration
evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "macro_f1"  # Primary metric for paper
    - "weighted_f1"
  
  batch_size: 32
  
  # Which split to use for final evaluation
  use_test_set: false  # If false, use validation set

# Logging and Output
logging:
  log_dir: "./logs/sa"
  log_file: "SA_Benchmark_{model}_{dataset}_{timestamp}.log"
  log_level: "INFO"
  
  # Save predictions
  save_predictions: true
  predictions_file: "./results/sa/{model}_{dataset}_predictions.csv"
  
  # Save metrics
  save_metrics: true
  metrics_file: "./results/sa/{model}_{dataset}_metrics.json"

# Checkpointing
checkpoints:
  save_checkpoints: true
  checkpoint_dir: "./checkpoints/sa"
  save_best_only: true
  monitor: "val_macro_f1"
  mode: "max"

# System Configuration
system:
  num_workers: 2
  pin_memory: true
  dataloader_persistent_workers: false
  
  # Memory tracking
  track_memory: true
  log_memory_usage: true

# Benchmark-specific Options
benchmark:
  # Run inference only (no training)
  inference_only: false
  
  # Load pretrained checkpoint
  load_checkpoint: null
  
  # Continue from checkpoint
  continue_from_checkpoint: false
  
  # Skip preprocessing if already done
  skip_preprocessing: false
  
  # Use streaming mode for large datasets
  use_streaming: false

